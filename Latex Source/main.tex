%%
%% This is file `sample-acmtog.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `acmtog')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmtog.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[acmtog]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2021}
\acmYear{2021}


%%
%% These commands are for a JOURNAL article.
\acmJournal{TOG}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Intelligent Tutoring for a College Course}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Mason Newman}
\email{mrnewman@colostate.edu}
\affiliation{%
  \institution{Colorado State University}
  \streetaddress{711 Oval Drive}
  \city{Fort Collins}
  \state{Colorado}
  \country{USA}
  \postcode{80521}
}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Newman}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Intelligent tutoring is a process by which a user learns material for a course and are given personalized feedback tools to enhance their learning. The intelligent tutoring functions on a number of psychological concepts. The high level format explored is a check in tool provided to students after each unit to examine their level of learning. The students learning should examine previous content up to what they have just learned. This tool should provide better learning for the course and for long term learning as a whole.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10003124.10010868</concept_id>
       <concept_desc>Human-centered computing~Web-based interaction</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003121.10003126</concept_id>
       <concept_desc>Human-centered computing~HCI theory, concepts and models</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Web-based interaction}
\ccsdesc[500]{Human-centered computing~HCI theory, concepts and models}
%%</ccs2012>

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{education, HCI, web-interfaces, deep learning}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Abstract}
School curriculums are developed to generate deep learning in students \cite{zuo2021higher}. Ebbinghaus theorized there exists a forgetting curve that states you serially forget items you have learned over time \cite{murre2015replication}. That’s why in a school curriculum, you may have cumulative exams that force you to relearn content every so often so you can remember it better. That also may explain why a large portion of what you learn in school is forgotten once you graduate. Unless we actively use information, we lose it. Knowing this, we can develop a piece of software that like a school curriculum actively reminds and quizzes us over content we want to remember and don’t actively use better. My project seeks to imitate an intelligent tutor, which theoretically takes information from a student, a curriculum, and adapts it based on the student’s current knowledge and the user interface \cite{bradavc2017intelligent}. My project aims to implement psychology techniques of learning into a computer program that can be used to aid learning outside of school in meaningful ways. The major question we're trying to ask is how can we use basic classroom input devices and computers to increase students long-term memory.

\section{Introduction}

\subsection{Intelligent Tutoring}
Intelligent tutoring dictates two types of feedback for learners: inner loop and outer loop feedback \cite{tacoma2021combined}. Inner loop feedback refers to feedback on an individual task or concept \cite{tacoma2021combined}. This may be feedback on an individual term from a unit. Outer loop feedback refers to higher level study materials and tasks to do to enhance learning \cite{tacoma2021combined}. Essentially, inner loop determines individual areas where students could improve, and outer loop aggregates all areas into a comprehensive tool. However, the implementation of these tools largely depends on the characteristics of the individual learning. Therefore, intelligent tutoring by necessity has to adapt to students needs and should start with a strong understanding of what kind of student is being taught.
\subsection{Inner Loop: Digital Learning Tools}
Tools like Quizlet have existed for many years at this point. Prior research has observed a positive correlation between interaction with digital flashcards and performance \cite{yuksel2020digital}. Therefore, we seek to test a peripheral feature of Quizlet tools, testing and feedback. Our experiment differs however, as it includes greater feedback than indicating incorrect or correct answers. Quizlet is limited by the amount of data a user puts into it. Therefore to represent the inner loop of intelligent tutoring, our tool will provide content from the course proactively for participants. The inner loop deals with individual cases of feedback for users. Therefore, our experiment will provide a short-term analysis on learning for a single section of a curriculum.  
\section{Motivation}
One of the major themes of psychology courses at CSU is childhood development. There are many theories about how we can best aid children to become better adults in the world. One of the best predictors of occupational, socioeconomic, and income success is education \cite{becker2019childhood}. In fact, education better predicts adult outcomes than family background and gender \cite{becker2019childhood}. Therefore, this research asks how can education be made more available to children who may have limited access? Additionally, how can we utilize modern technology to aid education so that during critical learning periods, children learn more and remember more of what’s taught to them? Personally, I have a deep interest in psychology and childhood development, so I’d like to create a project that can utilize the psychology methods I’ve learned about learning. However, it isn't feasible nor ethical to test on children for this project. So instead, my goal is to establish a fundamental concept of intelligent tutoring. The testing effect states that we learn better by making and taking tests than by rereading or restudying our notes \cite{su2021levels}. I would like to establish through the testing effect, are previously missed questions more important to go over than previous content, and does reviewing previous content influence learning as measured by a final exam. Specifically, if we missed content from a certain unit, does reviewing what we missed further our learning.

\section{Method}
I developed a web-based tool that pairs with a curriculum. My project utilized the Harvard CS50 free online class. Participants were instructed to first state some demographic information; this information will include gender, age, and technical skill (1-10 Likert scale). Then, participants read an introduction paragraph that highlights key terms that you would likely see at the beginning of this course. Participants then took 2 tests. The first and last test is the same for all participants. The second test was then be one of two conditions. The assisted feedback condition instructed users to review questions they got wrong and explained the reason the correct answer was correct. The control condition will simply take two separate quizzes. Unfortunately, other factors interfere with exam performance. We believe the results may be influenced by some extraneous variables. Some examples are cramming right before a test to improve short term memory (not long term memory), stress, sleep, etc. We will discuss limitations in greater detail in the discussion.

\subsection{Prototype}
The focus of my prototype is on the inner loop feedback of intelligent tutoring. The prototype is a web based tool similar to Quizlet which allows users to read content, take a quiz, and record results. Users are given immediate feedback on their performance and participants in the assisted feedback condition are given a rationale for questions they answered incorrectly. This is to simulate an adjusted curriculum provided for students in an intelligent tutoring program. The importance of immediate corrective feedback will be discussed later. Prior research also suggests that use of digital flashcards significantly increases learning \cite{yuksel2020digital}. Therefore, this experiment seeks to test if performative tests similar to ones you can take on Quizlet are beneficial to learning. In order to get a better understanding of why intelligent tutoring is effective, it's important to understand 

For this specific quiz, I used a partial passage from one of Harvard CS50 introductory courses. This means that this experiment will be aimed at people who are less technically savvy as more experienced CS majors will likely know the answers before reading the passage. I created 12 questions based off the passage and set the correct answer based on a random number generation. Additionally, for first quiz, I randomly picked the questions by a random number generator. I generated two sets of HTML code  which took users through a web based program for the experiment. The JavaScript for the assisted feedback condition was slightly modified to include constructive feedback for incorrect questions for the first part. Users are not allowed to navigate back to the initial paper. The only reference and tool for learning is the feedback given on which questions are correct or not.

\subsection{Participants}
Participants were 10 adult family members and friends who I invited in my home to participate in this experiment. As this experiment was aimed at less technically savvy people, I refrained from including any CS majors. Additionally, the content of the quizzes were beginner CS material, which may lead to skewed results due to prior knowledge. There were 5 male and 5 female participants. The average age of the participants was 33.8 years old. 5 participants were randomly selected for the control group and 5 participants were randomly selected for the assisted feedback condition. Participants did not complete the experiment in exchange for anything.

\subsection{Evaluation}
Participants were be split into two groups, assisted retest and normal retest. repeated standard testing, repeated content testing and repeated intelligent testing. Participants took a survey before the experiment for information on age, gender, and technical savvy. Participants were then instructed to read a short passage taken from one of the the Harvard CS50 pages. Participants then navigated to the first quiz when they were ready. Upon completion, both groups were given feedback for how many and which questions they got incorrect. However, participants in the assisted feedback condition were instructed to go back and read a short rationale for why the correct answer was correct. Then both groups completed the second quiz and their performance on both quizzes was recorded. Participants were then debriefed on the purpose of the experiment and which condition they were apart of verbally. Participants were allowed to leave at any time and completion was completely voluntary.

The experiment aims to test the short-term effect of immediate corrective feedback on performance. Some prior research shows spaced learning is more effective, but less enjoyable for those learning \cite{su2021levels}. Therefore, this experiment represents the most convenient, but not necessarily the most optimal way to learn.

\section{Results}
A two-way repeated measures ANOVA with replication was conducted to compare test performance for participants in the control group and the assisted feedback condition. Overall, participants in the assisted feedback condition answered more questions correctly (M = 3.8, SD = 0.84) than participants in the control group (M = 3.1, SD = 1.66). Our two-way ANOVA revealed that there was not a statistically significant interaction between the conditions F(3,16) = 1.00, p = .33. Follow up t-tests indicated that there was a significant difference between the assisted feedback condition and the control condition for quiz 2 t(8) = 1.90, p = .05 and a significant difference between performance for question 1 and 2 for the control condition. However, there was not a significant difference in performance between average test performance for the assisted feedback condition and the control group t(8) = 1.18, p = 0.13, nor was there a significant difference in performance between quiz 1 and quiz 2 for the assisted feedback condition.


% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
  \caption{Two-Way Repeated Measures ANOVA}
    \begin{tabular}{lrrrrrr}
    ANOVA &       &       &       &       &       &  \\
    \midrule
    \multicolumn{1}{c}{\textit{Source of Variation}} & \multicolumn{1}{c}{\textit{SS}} & \multicolumn{1}{c}{\textit{df}} & \multicolumn{1}{c}{\textit{MS}} & \multicolumn{1}{c}{\textit{F}} & \multicolumn{1}{c}{\textit{P-value}} & \multicolumn{1}{c}{\textit{F crit}} \\
    \midrule
    Sample & 2.45  & 1     & 2.45  & 1.96  & 0.18 & 4.49 \\
    Columns & 1.25  & 1     & 1.25  & 1     & 0.33 & 4.49 \\
    Interaction & 1.25  & 1     & 1.25  & 1     & 0.33 & 4.49 \\
    Within & 20    & 16    & 1.25  &       &       &  \\
          &       &       &       &       &       &  \\
    Total & 24.95 & 19    &       &       &       &  \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

\section{Discussion}
Although the initial two-way ANOVA didn't find any significant results, the follow up t-tests showed some significance. Although performance didn't significantly increase in the immediate feedback condition, it appears that performance significantly dropped in the control group. Therefore, feedback may not enhance learning, but help reduce the natural forgetting effect. However, this experiment cannot be used to determine long term effects on forgetting due to the testing window. The main focus of this experiment was on the effect of immediate corrective feedback. What we did not include in this study was a measure of user engagement. Prior research has shown that interaction with feedback is positively correlated to performance and getting the answer correct on the first try is negatively correlated with performance \cite{chen2018analyzing}. This result reflects that we are over confident learners, and our best learning comes when we review content we think we know well and content we don't know well. We also encouraged users to look at the feedback and engage with the rationale, but we have no measure of how much they used it. We could have used an introspective questionnaire to determine engagement, but we gaze measurement would be better. Eye fixation is commonly used to measure interest, desire, and likeness, so future research may utilize eye tracking technology to better understand how much users interact with feedback.

\subsection{Implications for Intelligent Tutoring}
If participants don't actively engage in their feedback, they won't see any benefit to intelligent tutoring. Computers can suggest feedback and study directions, but ultimately it's the users choice if they want to engage in the learning. Therefore, the next step for intelligent tutoring may be engaging users in meaningful ways. One large benefit of in person teaching is professor interaction. Prior research showed that depending on what kind of interaction students have with faculty and professors, they develop a positive or a negative opinion on the current racial diversity \cite{parker2020student}. This study reflects how important teacher student relationships are to perceptions for school and even desire to learn.

\section{Future Directions for Research}
We suggest future research should emphasize a longer period of learning and testing to better understand how feedback impacts learning and performance. Additionally, future research may utilize tools such as eye tracking to identify patterns of engagement in feedback. Additional research may include childhood development tools. One direction for early learning may be creating feedback through digital avatars if learning in a mixed environment. In the peak of covid-19, many kids became digital learners. Going forward, we should try to better understand how to teach digital learners as effectively as in person learners. However, as acknowledged in prior research, this is a difficult, time consuming task to test, as the experience is highly individualized and the results depend on the user just as much as the technology \cite{tacoma2021combined}. That's why this will be the next step in education.

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{citation}

\end{document}
\endinput
%%
%% End of file `sample-acmtog.tex'.
